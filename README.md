# KAS-ify Upstream Yocto Projects

## Quickstart

Run `make` after cloning and installing [dependencies](#host-dependencies) on your host. See [Make Target Explanation](#make-target-explanation) for details.

## What?
This is a prototype implementation for the automatic conversion of an arbitrary yocto project into one that supports the [kas build and configuration system](https://github.com/siemens/kas). We use the Variscite var-som-imx8mp SoM as the prototype's target platform. Variscite provides a [reference BSP: variscite-bsp-platform](https://github.com/varigit/variscite-bsp-platform/tree/mickledore) (supporting mickledore release), and [instructions for building it](https://variwiki.com/index.php?title=Yocto_Build_Release&release=mx8mp-yocto-mickledore-6.1.36_2.1.0-v1.3#Download_Yocto_Mickledore_based_on_NXP_BSP_L6.1.36_2.1.0).

## Why?

Like most SoC/SoM vendors, the BSP is based on [the BSP provided by the manufacturer of its underlying microprocessor, the NXP i.mx8mp](https://github.com/nxp-imx/meta-imx). which uses the ubiquitous but cumbersome yocto design patterns for:

1. Managing sources with [Google `repo`](https://gerrit.googlesource.com/git-repo/) xml manifests.
2. Managing configuration with files of various formats scattered throughout the working tree.

**[Kas](https://github.com/siemens/kas) is a much-needed layer of abstraction on top of yocto's complexities**, providing _sane defaults_, _intuitive and consolidated configuration management_, and _container-based builds_. To get started using kas requires manual conversion of a yocto project into [the kas configuration format](https://kas.readthedocs.io/en/latest/userguide/project-configuration.html#). This project simply automates this conversion process, attempting to **allow any yocto project to be built by kas without any manual intervention**.

As with any task automation, the benefits are amplified when you consider the frequency of the task's repetition. In lieu of making upstream contributions, Yocto best practice and software engineering experience dictates that layers shall not be modified in favor of patching out of tree or creating new layers. A primary benefit of this is to **enable the downstream yocto project to accept future upstream revisions and releases**. Therefore, downstream yocto projects are beholden to the project structure and tooling decisions made by the upstream projects they reference and use. kas is still only used in a vast minority of yocto projects.

## How?

This project uses GNU make, bash, jq, and yq. It was thrown together to demonstrate a [feature request for the kas development team](https://groups.google.com/g/kas-devel/c/Dk2AKNx0PQA), by a full-stack developer passionate about modernizing the embedded linux development stack, starting with the kas-ification of "traditional" yocto projects.

### Manual Build

It's always good when automating something to do it manually first, so let's break down the process of building a yocto distribution for the var-som-imx8mp, starting with the SoM manufacturer's [instructions](https://variwiki.com/index.php?title=Yocto_Build_Release&release=mx8mp-yocto-mickledore-6.1.36_2.1.0-v1.3#Download_Yocto_Mickledore_based_on_NXP_BSP_L6.1.36_2.1.0):

#### 1. Fetch, init, and sync the [BSP repo manifest](https://github.com/varigit/variscite-bsp-platform/blob/mickledore/imx-6.1.36-2.1.0.xml) 

```
mkdir manual && cd manual
repo init -u https://github.com/varigit/variscite-bsp-platform.git -b mickledore -m imx-6.1.36-2.1.0.xml
repo sync -j$(nproc)
```

#### 2. Setup the Build Environment 

```
MACHINE=imx8mp-var-dart DISTRO=fsl-imx-xwayland BUILD_DIR=build_xwayland . var-setup-release.sh $BUILD_DIR
```

This setup script creates the relative $BUILD_DIR, and generates top-level [user configuration](https://docs.yoctoproject.org/singleindex.html#user-configuration) files in a `conf/` subdirectory. As documented in the [user configuration](https://docs.yoctoproject.org/singleindex.html#user-configuration) section of the yocto manual, there are 4 user configuration files that _may_ appear within the `build/` directory at the top level of a yocto project:

|user config file   |purpose                                                               |origin/owner                                                     |
|-------------------|----------------------------------------------------------------------|-----------------------------------------------------------------|
|conf/local.conf    | customize bitbake options for local build environment/infrastructure | generated by setup-environment                                  |
|conf/bblayers.conf | defines layers and their locations                                   | generated by setup-environment                                  |
|conf/auto.conf     | anything?                                                            | in-tree of the upstream super-repo (not generated by setup-env) |
|conf/site.conf     | specifies multiple build directories                                 | in-tree of the upstream super-repo (not generated by setup-env) |

Also from the [user configuration section of the yocto manual](https://docs.yoctoproject.org/singleindex.html#user-configuration):

> It is important to understand that the [OpenEmbedded Build System](https://docs.yoctoproject.org/singleindex.html#term-OpenEmbedded-Build-System) reads the configuration files in a specific order: 
>   1. site.conf
>   2. auto.conf
>   3. local.conf
> And, the build system applies the normal assignment statement rules as described in the [“Syntax and Operators” chapter of the BitBake User Manual](https://docs.yoctoproject.org/bitbake/2.8/bitbake-user-manual/bitbake-user-manual-metadata.html). Because the files are parsed in a specific order, variable assignments for the same variable could be affected. For example, if the auto.conf file and the local.conf set variable1 to different values, because the build system parses local.conf after auto.conf, variable1 is assigned the value from the local.conf file.

#### How to identify what setup-environment script to run from a super-repo working tree

TL;DR; Because this is wildly vendor- and repo-specific, kas must be told the path to this executable to run by the user, who typically gets this from the upstream project's documentation.

We do assume that there is a single script to run, which wraps any other required scripts. This appears to be best practice in the Yocto Project manual and the BSP Developers Manual.

##### Common Upstream Design Pattern: Symbolic Links

A common pattern is to abstract this with a single static script name at the root of the super-repo that is a symlink to the appropriate script located in a layer subdirectory of the checkout. Symbolic links are supported by both of the super-repo methods kas supports: 

1. Google's repo-tool and its manifest schema support [xml elements for specifying symlinks](https://gerrit.googlesource.com/git-repo/+/master/docs/manifest-format.md#Element-linkfile).
1. git repos can contain [symlinks which are simply files](https://man7.org/linux/man-pages/man7/symlink.7.html#DESCRIPTION).

Some detailed notes on how symlinks are handled in the BSP of our prototype target, the Variscite SoM:

1. top-level script `var-setup-release.sh` is a symlink to `sources/meta-variscite-sdk-imx/scripts/var-setup-release.sh`.
1. `sources/meta-variscite-sdk-imx/` is the path where the repo tool cloned https://github.com/varigit/meta-variscite-sdk-imx. This mapping and the symlink creation was all dictated by these elements in the manifest xml:
    ```
    <project name="meta-variscite-sdk-imx"    path="sources/meta-variscite-sdk-imx"    remote="variscite"   revision="3d0c94f6b126c121921645eb0a4abba0151ccf43" upstream="mickledore-var02">
      <linkfile src="scripts/var-setup-release.sh" dest="var-setup-release.sh"/>
      <linkfile src="dynamic-layers/var-debian/scripts/var-setup-debian.sh" dest="var-setup-debian.sh"/>
    </project>
    <remote name="variscite"   fetch="https://github.com/varigit"/>
    ```
    1. `sources/meta-variscite-sdk-imx/scripts/var-setup-release.sh` does the following:
        1. calls the corresponding imx script provided by NXP (`imx-setup-release.sh`) which generates `conf/bblayers.conf` and `conf/local.conf`.
        1. Post-processes the generated configuration files by:
            1. Removing several layer lines from `conf/bblayers.conf`.
            1. Removing an apt package management line from `conf/local.conf`.

#### 3. Do the Build

This is typically done monolithically in one command:

```
bitbake fsl-image-gui
```

Although, I prefer to separate the Pre-Fetch and Build Stages:

```
bitbake --runall fetch fsl-image-gui
bitbake fsl-image-gui
```

### KAS-ification

The DIY mindset and open-ended flexibility of the [OpenEmbedded Build System](https://docs.yoctoproject.org/singleindex.html#term-OpenEmbedded-Build-System) may have been a blessing for [NIH engineering cultures](https://en.wikipedia.org/wiki/Not_invented_here) and the early growth of the Yocto Project, but it is a curse for those of us that want to transform the project into a modern, scalable, declarative system, together and in the open.

The infinite potential for complexity in setup-environment script implementations constrains us to a single viable solution that is both simple and resilient: **automate the existing checkout and configuration processes**.

#### Pseudo-code

To generate a kas config from an arbitrary yocto project, providing the prototype for a new kas sub-command like `kas import`, we have currently implemented this in the script `mkasconf`:

```
NAME
       mkasconf - migrate any Yocto project to kas configuration

SYNOPSIS
       mkasconf URL <setup-environment-script>

DESCRIPTION
       mkasconf integrates arbitrary Yocto projects into kas-based projects. Implementing the following pseudocode:

       1. fetch sources from URL arg, either:
           1. `repo init $URL && repo sync`
           1. `git clone --recurse-submodules $URL`
       1. execute <setup-environment-script>
       1. convert and merge the user configuration in `conf/{local,bblayers,site,auto}.conf` into kas config yaml
           1. injecting `header.super-repo-origin: "URL"` in the kas.yml. 
                   1. This field uniquely identifies a specific revision of the super-repo.

       The generated `kas.yml` can be used within the normal kas context, either a monolithic top-level project corresponding to the converted Yocto project, or as a nested layer that can be included from a higher-level kas project. 

       The intent is that this script will become part of `kas` workflows and commands, enables the ongoing acceptance of changes from kas-unaware upstream Yocto projects, by implementing the following logic (in kas):

        1. keep/cache/commit the kas.yml generated by mkasconf, but...
        1. compare local kas.yml `header.super-repo-origin` to the field in the .yml supplied in the kas call vs the one in the kas.yml in the kas working tree.
            1. If these fields are different, it is because the user intends to accept some upstream changes to the super-repo, and they have manually changed the super-repo-origin.

ARGS
    URL
        Specifies either:
            - an HTTP-GETtable Google repo-tool xml manifest file defining all layer repositories
            - a git cloneable super-repository defining layer repositories as submodules
    SETUPENVPATH
        path to the setup-environment script, relative to the checkout/sources root, that would be executed when setting up manual yocto build environment.
```

# Make Target Explanation

The default make target is `kasbuild`, which is at the top of the dependency graph, i.e. it is dependent on all the other targets.

Use `make help` for more information about the make targets.

```
Usage:  make [OPTION] ... [TARGET] ...

                    TARGET  DESCRIPTION
```

# Host Dependencies

The host needs these installed. All other dependencies are handled by container environments.

## bash
https://www.gnu.org/software/bash/manual/bash.html#Installing-Bash

## GNU make
https://www.gnu.org/software/make/manual/make.html#Overview

## docker or podman
Required to manage containers.
